{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81609416",
   "metadata": {},
   "source": [
    "Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18293557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Auto-selected sheet: DADOSTB\n",
      "[DEBUG] Read sheet 'DADOSTB' with shape (30282, 102)\n",
      "[DEBUG] Top forma values:\n",
      "forma\n",
      "1.0    27749\n",
      "2.0     2240\n",
      "3.0      283\n",
      "Name: count, dtype: int64\n",
      "[DEBUG] Filtered 27749 rows by numeric code 1\n",
      "[DEBUG] Detected: date=dt_notific, year=nu_ano, month=None, cases=nu_numero, pop=None\n",
      "[DEBUG] Parsed date column and extracted year/month.\n",
      "[DEBUG] Using explicit case column 'nu_numero'\n",
      "[DEBUG] Annual CSV saved: processed_data\\annual_pulmonary_tb_by_year.csv\n",
      "[DEBUG] Monthly CSV saved: processed_data\\monthly_pulmonary_tb_by_month.csv\n",
      "[DEBUG] Monthly with outlier flags saved: processed_data\\monthly_pulmonary_tb_by_month_flagged_outliers.csv\n",
      "[DEBUG] Filtered pulmonary rows saved: processed_data\\filtered_pulmonary_tb_rows.csv\n",
      "[DEBUG] Processing complete.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Preprocessing.py\n",
    "\n",
    "EN:\n",
    "Main ingestion and preprocessing script for TB dataset.\n",
    "Filters only pulmonary TB (forma == 1), detects date/case/population columns,\n",
    "performs minimal preprocessing (missing handling & outlier marking),\n",
    "and writes clean mnemonic CSVs into the folder 'processed_data/'.\n",
    "\n",
    "PT-BR:\n",
    "Script principal de ingestão e pré-processamento do conjunto de TB.\n",
    "Filtra apenas tuberculose pulmonar (forma == 1), detecta colunas de data/casos/população,\n",
    "executa pré-processamento mínimo (tratamento de missing e marcação de outliers),\n",
    "e grava CSVs mnemônicos na pasta 'processed_data/'.\n",
    "\"\"\"\n",
    "\n",
    "# =======================================================\n",
    "# GLOBAL DEBUGGING FLAGS\n",
    "# =======================================================\n",
    "DEBUG = True          # True = show debug messages / False = silent\n",
    "LANGUAGE = \"EN\"       # \"EN\" or \"PT\"\n",
    "# =======================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import unicodedata\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# DEBUG PRINT FUNCTION\n",
    "# =======================================================\n",
    "def debug(msg_en: str, msg_pt: str = \"\"):\n",
    "    \"\"\"\n",
    "    EN:\n",
    "        Prints debug messages depending on DEBUG flag and LANGUAGE setting.\n",
    "    PT-BR:\n",
    "        Imprime mensagens de debug dependendo da flag DEBUG e configuração LANGUAGE.\n",
    "    \"\"\"\n",
    "    if not DEBUG:\n",
    "        return\n",
    "    if LANGUAGE.upper() == \"EN\":\n",
    "        print(f\"[DEBUG] {msg_en}\")\n",
    "    else:\n",
    "        print(f\"[DEBUG] {msg_pt if msg_pt else msg_en}\")\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# CONFIG\n",
    "# =======================================================\n",
    "\n",
    "PATH_XLSX = \"tb.xlsx\"           # original data file\n",
    "SHEET_NAME: Optional[str] = None\n",
    "FORMA_COL = \"forma\"\n",
    "PULMONARY_CODE = 1\n",
    "OUTPUT_FOLDER = Path(\"processed_data\")\n",
    "\n",
    "MIN_ROWS_FOR_MONTHLY = 12\n",
    "REMOVE_OUTLIERS = False\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# UTILITIES\n",
    "# =======================================================\n",
    "\n",
    "def normalize_colname(s: str) -> str:\n",
    "    \"\"\"Normalize column name (EN/PT).\"\"\"\n",
    "    s = str(s)\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ASCII\", \"ignore\").decode()\n",
    "    return s.strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "def detect_best_sheet(path: str) -> str:\n",
    "    \"\"\"Auto-selects sheet by keyword score.\"\"\"\n",
    "    xls = pd.ExcelFile(path)\n",
    "    sheets = xls.sheet_names\n",
    "    keywords = [\"tb\", \"tuberculose\", \"dados\", \"notificado\", \"notific\", \"registro\", \"caso\", \"case\", \"base\", \"raw\"]\n",
    "    scores = []\n",
    "\n",
    "    for sh in sheets:\n",
    "        try:\n",
    "            df_head = pd.read_excel(path, sheet_name=sh, nrows=5)\n",
    "            cols_text = \" \".join([str(c).lower() for c in df_head.columns])\n",
    "            score = sum(k in cols_text for k in keywords) + sum(k in sh.lower() for k in keywords)\n",
    "            scores.append((sh, score))\n",
    "        except:\n",
    "            scores.append((sh, 0))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    chosen = scores[0][0] if scores else sheets[0]\n",
    "\n",
    "    debug(\n",
    "        f\"Auto-selected sheet: {chosen}\",\n",
    "        f\"Sheet selecionada automaticamente: {chosen}\"\n",
    "    )\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def read_data(path: str, sheet: Optional[str]):\n",
    "    \"\"\"Reads sheet and normalizes columns.\"\"\"\n",
    "    if sheet is None:\n",
    "        sheet = detect_best_sheet(path)\n",
    "\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    df.columns = [normalize_colname(c) for c in df.columns]\n",
    "\n",
    "    debug(\n",
    "        f\"Read sheet '{sheet}' with shape {df.shape}\",\n",
    "        f\"Lida sheet '{sheet}' com shape {df.shape}\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def try_parse_date_column(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Robust date parsing.\"\"\"\n",
    "    parsed = []\n",
    "    for v in series:\n",
    "        try:\n",
    "            if pd.isna(v):\n",
    "                parsed.append(pd.NaT)\n",
    "            else:\n",
    "                parsed.append(parser.parse(str(v), dayfirst=True))\n",
    "        except:\n",
    "            parsed.append(pd.NaT)\n",
    "    return pd.to_datetime(parsed)\n",
    "\n",
    "\n",
    "def find_column_by_candidates(df: pd.DataFrame, candidates: list) -> Optional[str]:\n",
    "    \"\"\"Finds first column matching substrings.\"\"\"\n",
    "    for cand in candidates:\n",
    "        for c in df.columns:\n",
    "            if cand in c:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def mark_outliers_iqr(series: pd.Series, multiplier: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Marks outliers using IQR rule.\"\"\"\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - multiplier * iqr\n",
    "    upper = q3 + multiplier * iqr\n",
    "    return (series < lower) | (series > upper)\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# MAIN PIPELINE\n",
    "# =======================================================\n",
    "\n",
    "def process_tb(path_xlsx, sheet_name, forma_col, pulmonary_code, output_folder):\n",
    "    \"\"\"Core processing pipeline (EN/PT).\"\"\"\n",
    "\n",
    "    df = read_data(path_xlsx, sheet_name)\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    forma_col_norm = normalize_colname(forma_col)\n",
    "    if forma_col_norm not in df.columns:\n",
    "        candidate = find_column_by_candidates(df, [\"forma\", \"tipo\", \"class\", \"clin\"])\n",
    "        if candidate:\n",
    "            forma_col_norm = candidate\n",
    "            debug(\n",
    "                f\"Detected forma column -> {candidate}\",\n",
    "                f\"Coluna 'forma' detectada -> {candidate}\"\n",
    "            )\n",
    "        else:\n",
    "            debug(\n",
    "                \"ERROR: 'forma' column not found.\",\n",
    "                \"ERRO: coluna 'forma' não encontrada.\"\n",
    "            )\n",
    "            raise SystemExit(1)\n",
    "\n",
    "    # Show distribution (debug)\n",
    "    if forma_col_norm in df.columns:\n",
    "        try:\n",
    "            vc = df[forma_col_norm].value_counts()\n",
    "            debug(\n",
    "                f\"Top forma values:\\n{vc}\",\n",
    "                f\"Valores na coluna forma:\\n{vc}\"\n",
    "            )\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Filter pulmonary TB\n",
    "    df_filtered = pd.DataFrame()\n",
    "    try:\n",
    "        mask = pd.to_numeric(df[forma_col_norm], errors=\"coerce\") == pulmonary_code\n",
    "        if mask.sum() > 0:\n",
    "            df_filtered = df.loc[mask].copy()\n",
    "            debug(\n",
    "                f\"Filtered {df_filtered.shape[0]} rows by numeric code {pulmonary_code}\",\n",
    "                f\"Filtradas {df_filtered.shape[0]} linhas usando código numérico {pulmonary_code}\"\n",
    "            )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        mask = df[forma_col_norm].astype(str).str.strip().str.lower() == str(pulmonary_code)\n",
    "        df_filtered = df.loc[mask].copy()\n",
    "        debug(\n",
    "            f\"Filtered {df_filtered.shape[0]} rows by string match\",\n",
    "            f\"Filtradas {df_filtered.shape[0]} linhas via comparação por string\"\n",
    "        )\n",
    "\n",
    "    if df_filtered.empty:\n",
    "        debug(\n",
    "            \"Filtering returned ZERO rows. Saving a sample for inspection.\",\n",
    "            \"Filtro retornou ZERO linhas. Salvando amostra para inspeção.\"\n",
    "        )\n",
    "        df.head(100).to_csv(output_folder / \"sample_inspection.csv\", index=False)\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    # Look for columns\n",
    "    DATE_CAND = [\"data\", \"date\", \"data_notificacao\", \"dt_notif\"]\n",
    "    YEAR_CAND = [\"ano\", \"year\"]\n",
    "    MONTH_CAND = [\"mes\", \"month\"]\n",
    "    CASE_CAND = [\"casos\", \"cases\", \"n_casos\", \"count\", \"numero\"]\n",
    "    POP_CAND = [\"pop\", \"population\", \"populacao\"]\n",
    "\n",
    "    date_col = find_column_by_candidates(df_filtered, DATE_CAND)\n",
    "    year_col = find_column_by_candidates(df_filtered, YEAR_CAND)\n",
    "    month_col = find_column_by_candidates(df_filtered, MONTH_CAND)\n",
    "    case_col = find_column_by_candidates(df_filtered, CASE_CAND)\n",
    "    pop_col = find_column_by_candidates(df_filtered, POP_CAND)\n",
    "\n",
    "    debug(\n",
    "        f\"Detected: date={date_col}, year={year_col}, month={month_col}, cases={case_col}, pop={pop_col}\",\n",
    "        f\"Detectado: data={date_col}, ano={year_col}, mes={month_col}, casos={case_col}, pop={pop_col}\"\n",
    "    )\n",
    "\n",
    "    # Date parsing\n",
    "    if date_col:\n",
    "        df_filtered[\"date_parsed\"] = try_parse_date_column(df_filtered[date_col])\n",
    "        df_filtered[\"year\"] = df_filtered[\"date_parsed\"].dt.year\n",
    "        df_filtered[\"month\"] = df_filtered[\"date_parsed\"].dt.month\n",
    "        debug(\n",
    "            \"Parsed date column and extracted year/month.\",\n",
    "            \"Parseada coluna data e extraído ano/mês.\"\n",
    "        )\n",
    "    else:\n",
    "        if year_col:\n",
    "            df_filtered[\"year\"] = pd.to_numeric(df_filtered[year_col], errors=\"coerce\")\n",
    "        if month_col:\n",
    "            df_filtered[\"month\"] = pd.to_numeric(df_filtered[month_col], errors=\"coerce\")\n",
    "\n",
    "    # Case handling\n",
    "    if case_col:\n",
    "        df_filtered[\"cases_raw\"] = pd.to_numeric(df_filtered[case_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "        debug(\n",
    "            f\"Using explicit case column '{case_col}'\",\n",
    "            f\"Usando coluna explícita de casos '{case_col}'\"\n",
    "        )\n",
    "    else:\n",
    "        df_filtered[\"cases_raw\"] = 1\n",
    "        debug(\n",
    "            \"No case column found -> assuming one row = one case.\",\n",
    "            \"Coluna de casos não encontrada -> assumindo 1 linha = 1 caso.\"\n",
    "        )\n",
    "\n",
    "    # Population mapping\n",
    "    population_map = None\n",
    "    if pop_col and year_col:\n",
    "        try:\n",
    "            df_pop = df[[year_col, pop_col]].drop_duplicates()\n",
    "            df_pop = df_pop.dropna()\n",
    "            population_map = dict(zip(df_pop[year_col], df_pop[pop_col]))\n",
    "            debug(\n",
    "                \"Population mapping created.\",\n",
    "                \"Mapeamento de população criado.\"\n",
    "            )\n",
    "        except:\n",
    "            debug(\n",
    "                \"Could not create population map.\",\n",
    "                \"Não foi possível criar mapa de população.\"\n",
    "            )\n",
    "\n",
    "    # ---------------------------\n",
    "    # Aggregations\n",
    "    # ---------------------------\n",
    "    # Annual\n",
    "    if \"year\" in df_filtered.columns:\n",
    "        annual = (\n",
    "            df_filtered.groupby(\"year\")[\"cases_raw\"]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"cases_raw\": \"cases\"})\n",
    "        )\n",
    "\n",
    "        if population_map:\n",
    "            annual[\"population\"] = annual[\"year\"].map(population_map)\n",
    "            annual[\"incidence_per_100k\"] = (annual[\"cases\"] / annual[\"population\"]) * 1e5\n",
    "        else:\n",
    "            annual[\"population\"] = pd.NA\n",
    "            annual[\"incidence_per_100k\"] = pd.NA\n",
    "\n",
    "        annual_path = output_folder / \"annual_pulmonary_tb_by_year.csv\"\n",
    "        annual.to_csv(annual_path, index=False)\n",
    "\n",
    "        debug(\n",
    "            f\"Annual CSV saved: {annual_path}\",\n",
    "            f\"CSV anual salvo: {annual_path}\"\n",
    "        )\n",
    "\n",
    "    # Monthly\n",
    "    monthly = None\n",
    "    if \"year\" in df_filtered.columns and \"month\" in df_filtered.columns:\n",
    "        valid = df_filtered[\"month\"].notna().sum()\n",
    "        if valid > 0:\n",
    "            if \"nu_notific\" in df_filtered.columns:\n",
    "                monthly = (\n",
    "                    df_filtered\n",
    "                    .groupby([\"year\", \"month\"])[\"nu_notific\"]\n",
    "                    .nunique()\n",
    "                    .reset_index()\n",
    "                    .rename(columns={\"nu_notific\": \"cases\"})\n",
    "                )\n",
    "            else:\n",
    "                # fallback: count rows if no notification ID exists\n",
    "                monthly = (\n",
    "                    df_filtered\n",
    "                    .groupby([\"year\", \"month\"])\n",
    "                    .size()\n",
    "                    .reset_index(name=\"cases\")\n",
    "                )\n",
    "\n",
    "            monthly[\"date\"] = pd.to_datetime(\n",
    "                monthly[\"year\"].astype(int).astype(str)\n",
    "                + \"-\"\n",
    "                + monthly[\"month\"].astype(int).astype(str)\n",
    "                + \"-01\",\n",
    "                errors=\"coerce\",\n",
    "            )\n",
    "\n",
    "            monthly_path = output_folder / \"monthly_pulmonary_tb_by_month.csv\"\n",
    "            monthly.to_csv(monthly_path, index=False)\n",
    "\n",
    "            debug(\n",
    "                f\"Monthly CSV saved: {monthly_path}\",\n",
    "                f\"CSV mensal salvo: {monthly_path}\"\n",
    "            )\n",
    "\n",
    "            # OPTIONAL outlier flag\n",
    "            monthly[\"is_outlier_iqr\"] = mark_outliers_iqr(monthly[\"cases\"])\n",
    "            flagged_path = output_folder / \"monthly_pulmonary_tb_by_month_flagged_outliers.csv\"\n",
    "            monthly.to_csv(flagged_path, index=False)\n",
    "\n",
    "            debug(\n",
    "                f\"Monthly with outlier flags saved: {flagged_path}\",\n",
    "                f\"Mensal com outliers marcado salvo: {flagged_path}\"\n",
    "            )\n",
    "\n",
    "    # Save filtered rows\n",
    "    filtered_path = output_folder / \"filtered_pulmonary_tb_rows.csv\"\n",
    "    df_filtered.to_csv(filtered_path, index=False)\n",
    "\n",
    "    debug(\n",
    "        f\"Filtered pulmonary rows saved: {filtered_path}\",\n",
    "        f\"Linhas filtradas salvas: {filtered_path}\"\n",
    "    )\n",
    "\n",
    "    debug(\n",
    "        \"Processing complete.\",\n",
    "        \"Processamento concluído.\"\n",
    "    )\n",
    "\n",
    "# =======================================================\n",
    "# ENTRY POINT\n",
    "# =======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    process_tb(\n",
    "        path_xlsx=PATH_XLSX,\n",
    "        sheet_name=SHEET_NAME,\n",
    "        forma_col=FORMA_COL,\n",
    "        pulmonary_code=PULMONARY_CODE,\n",
    "        output_folder=OUTPUT_FOLDER,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
